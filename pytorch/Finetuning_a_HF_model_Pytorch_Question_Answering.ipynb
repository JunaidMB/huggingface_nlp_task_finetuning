{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YbIBXcexEdo"
      },
      "source": [
        "# Finetune a DistilBERT model on the SQuAD Dataset\n",
        "\n",
        "Task Description: Involves finetuning a model on QA pairs such that a model can answer particular types of questions.\n",
        "\n",
        "Original Tutorial: https://huggingface.co/docs/transformers/tasks/question_answering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfiVGwyMxKEE"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets evaluate accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocHWFEgMxUmn"
      },
      "source": [
        "# Load SQuAD dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geYs0U6JxRxV"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "squad = load_dataset(\"squad\", split=\"train[:5000]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2KnqDXDgh6d"
      },
      "outputs": [],
      "source": [
        "squad = squad.train_test_split(test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtcEya7Kx4-x",
        "outputId": "23f8374e-ca05-40fa-fe12-b5495292bd25"
      },
      "outputs": [],
      "source": [
        "# Look at the data\n",
        "import pprint\n",
        "pprint.pprint(squad['train'][0])\n",
        "\n",
        "# The text column is our model input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbtvEgvlyEbI",
        "outputId": "568b59d0-b8ff-45b0-b59e-21bd61f0cc8a"
      },
      "outputs": [],
      "source": [
        "# Preprocessing\n",
        "## Load Model\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdqW8fPkMrod"
      },
      "outputs": [],
      "source": [
        "# Check Model\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si2rzi9-MrtZ"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Parameter name: {name}\")\n",
        "    print(f\"Requires gradients: {param.requires_grad}\")\n",
        "    print(f\"Parameter shape: {param.shape}\")\n",
        "    print(\"=\" * 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J42lAQwrMsAZ"
      },
      "outputs": [],
      "source": [
        "# # Optional: Specify layers to fine tune and which to freeze by setting requires grad to true and false\n",
        "# layers_to_fine_tune = ['decoder.final_layer_norm.weight']\n",
        "\n",
        "# # Freeze layers\n",
        "# for name, param in model.named_parameters():\n",
        "#     if not any(layer_name in name for layer_name in layers_to_fine_tune):\n",
        "#         param.requires_grad = False\n",
        "\n",
        "# # Unfreeze Fine-tune layers\n",
        "# for name, param in model.named_parameters():\n",
        "#     if any(layer_name in name for layer_name in layers_to_fine_tune):\n",
        "#         param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG9COA2JytEJ"
      },
      "source": [
        "# Preprocessing\n",
        "We need to create a preprocess function that we will apply to every instance in the dataset. The preprocess function needs to:\n",
        "\n",
        "1. Some examples in a dataset may have a very long context that exceeds the maximum input length of the model. To deal with longer sequences, truncate only the context by setting truncation=\"only_second\".\n",
        "\n",
        "2. Next, map the start and end positions of the answer to the original context by setting return_offset_mapping=True.\n",
        "\n",
        "3. With the mapping in hand, now you can find the start and end tokens of the answer. Use the sequence_ids method to find which part of the offset corresponds to the question and which corresponds to the context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wnFWGL0epiW"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=384,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "6b97da18b34245e98e44511fe7ef5ceb",
            "83af1af3748940e6b46306cbb8ad1925",
            "6d681fdea4a44249a13ba89774d9dc87",
            "45c6ef85eaa342d687a1012d46853cfa",
            "e4d7baf85a424ac8ad52d13b386a79d3",
            "a003b76d8a1c488d950166cead2c76f2",
            "0e76cb13e1754e71927fad2f6f4ed6f0",
            "2c60d4dafcd24bca979781a87c0c6aef",
            "67bd2fc70a6a439c9051695a0ad3e801",
            "0f1a0ed81d74449dabdae5b7c7a5cb5c",
            "bfd4c6bbfa53491bbad60b1343694c00",
            "21b63b5441244ee495eee48ab80648a5",
            "0b1f0dd2a2bf445384f705190479c7a2",
            "4bd1e03af5064022990978c0c65419be",
            "8447f0aee645445299b6eb2e64d1e20f",
            "e127d4a1f43f420fa539d017e65cb5f5",
            "4bbb7d11d9c24695a2eef2b77afd2b9d",
            "64a996940ad04eae80f58bdb54e36356",
            "bcd50b1507504cc1ba151b9805d470ab",
            "5e87ef095bdc40839fc28c59970cf3ef",
            "cbf3696088234fb49fc50d04bd1c9140",
            "57fbbea4184f4a70ab445ada6c8c63e8"
          ]
        },
        "id": "4pYKGGO7zzYM",
        "outputId": "93224961-de54-40c4-e476-04f3112de3bc"
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing over entire dataset - batched = True process multiple elements of the datasets\n",
        "tokenized_squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBMLy0Jf0oHo",
        "outputId": "2eee06d3-6e9e-4f5d-e17a-f5b0490a1c3f"
      },
      "outputs": [],
      "source": [
        "tokenized_squad['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOLxnG5Ze2OC"
      },
      "outputs": [],
      "source": [
        "# Create a batch of examples, with dynamic padding. Create the appropriate collator function\n",
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n84Gl8_qe9Ke"
      },
      "source": [
        "# Evaluate\n",
        "\n",
        "We want to create a `compute_metrics` function that monitors a metric during training. For this task, use the accuracy metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stvQKOl0fEBi"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzO5q20INAtf",
        "outputId": "61f9ab7d-e64c-40d5-9231-7257a3c07584"
      },
      "outputs": [],
      "source": [
        "tokenized_squad_trch = tokenized_squad\n",
        "\n",
        "tokenized_squad_trch.set_format(\"torch\")\n",
        "tokenized_squad_trch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_asvIFFNT_c",
        "outputId": "b27d5e7b-31b6-453b-e9c7-d9578af66ecd"
      },
      "outputs": [],
      "source": [
        "tokenized_squad_trch['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeMo-3FuNW79"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_squad_trch['train'], shuffle = True, batch_size = 16, collate_fn=data_collator\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    tokenized_squad_trch['test'], shuffle = True, batch_size = 16, collate_fn=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpNzSysENazV",
        "outputId": "ecb31d88-d14f-4e97-92a6-57e8f349af5e"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "batch = next(iter(train_dataloader))\n",
        "\n",
        "#print(batch)\n",
        "print(len(train_dataloader))\n",
        "print(f\"input_ids batch shape: {batch['input_ids'].shape}\")\n",
        "print(f\"attention_mask batch shape: {batch['attention_mask'].shape}\")\n",
        "#print(f\"labels batch shape: {batch.labels.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gwp1TEMnOkrY"
      },
      "source": [
        "# Train Model Using PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytY_-P8FOm5J",
        "outputId": "e2220cbe-a217-4312-af2c-d700eff99337"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from transformers import AdamW, get_scheduler\n",
        "import torch\n",
        "\n",
        "# Define Optimiser\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "\n",
        "# Define Loss Function\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "def compute_metrics(predictions, labels):\n",
        "    #predictions = torch.argmax(predictions, axis=1)\n",
        "\n",
        "    return accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# Initialize variables to track the best model\n",
        "best_loss = float('inf')\n",
        "best_checkpoint_path = None\n",
        "\n",
        "# Collect Statistics\n",
        "train_loss = []\n",
        "train_start_pos_metrics = []\n",
        "train_end_pos_metrics = []\n",
        "test_start_pos_metrics = []\n",
        "test_end_pos_metrics = []\n",
        "\n",
        "## Place training on a GPU\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)\n",
        "model.to(device)\n",
        "\n",
        "# Define Learning Rate Scheduler\n",
        "num_epochs = 1\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ctm_7WNO1ia",
        "outputId": "305a4f7a-3a38-4c57-c9b7-89453d2efce8"
      },
      "outputs": [],
      "source": [
        "# Set up a list to store checkpoints\n",
        "checkpoint_paths = []\n",
        "\n",
        "model.train()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        # Set Gradients to 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Perform a forward model pass\n",
        "        ## Put the batch onto a GPU\n",
        "        batch = {k: v.to(device) for (k, v) in batch.items()}\n",
        "\n",
        "        ## Forward Pass\n",
        "        outputs = model(**batch)\n",
        "\n",
        "        # Compute Loss\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Compute Metric\n",
        "        start_logits = outputs.start_logits\n",
        "        end_logits = outputs.end_logits\n",
        "\n",
        "        start_pos_predictions = torch.argmax(start_logits, dim = -1)\n",
        "        end_pos_predictions = torch.argmax(end_logits, dim = -1)\n",
        "\n",
        "        start_pos_labels = batch['start_positions']\n",
        "        end_pos_labels = batch['end_positions']\n",
        "\n",
        "        start_pos_metrics = compute_metrics(predictions= start_pos_predictions, labels=start_pos_labels)\n",
        "        end_pos_metrics = compute_metrics(predictions= end_pos_predictions, labels=end_pos_labels)\n",
        "\n",
        "        # Store Metrics\n",
        "        train_loss.append(float(loss))\n",
        "        train_start_pos_metrics.append(start_pos_metrics)\n",
        "        train_end_pos_metrics.append(end_pos_metrics)\n",
        "\n",
        "        # Backward pass to update parameters\n",
        "        ## Compute fradients with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Optimizer step\n",
        "        ## Use the computed gradients to update the model parameters - adjust parameters in the direction that reduces the loss\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update Learning Rate - according to a schedule. This adjusts learning rate dynamically\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        # Print Progress\n",
        "        print(f\"epoch {epoch} batch_number {i} loss {loss} start_pos_metrics {start_pos_metrics} end_pos_metrics {end_pos_metrics}\")\n",
        "\n",
        "    # Save checkpoint at certain intervals\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "        'metrics': start_pos_metrics,\n",
        "        # Add other relevant information if needed\n",
        "    }\n",
        "    checkpoint_path = f'checkpoint_epoch_{epoch}_batch_{i}.bin'\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    checkpoint_paths.append(checkpoint_path)\n",
        "\n",
        "    # Update best_loss and best_checkpoint_path if needed\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "        best_checkpoint_path = checkpoint_path\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XNT_b2kRtq_"
      },
      "outputs": [],
      "source": [
        "# Load the best model checkpoint\n",
        "best_checkpoint = torch.load(best_checkpoint_path)\n",
        "\n",
        "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(best_checkpoint['optimizer_state_dict'])\n",
        "\n",
        "best_epoch = best_checkpoint['epoch']\n",
        "best_loss = best_checkpoint['loss']\n",
        "best_metrics = best_checkpoint['metrics']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2EPXlUVRx7W",
        "outputId": "4b32d155-fe8f-4cd1-fcee-2c7d833294c6"
      },
      "outputs": [],
      "source": [
        "print(best_epoch)\n",
        "print(best_loss)\n",
        "print(best_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW_Oi1djR1yn",
        "outputId": "919ac8c8-7f24-418e-8d75-c66dbcce6e14"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "eval_start_pos_metrics = []\n",
        "eval_end_pos_metrics = []\n",
        "for epoch in range(num_epochs):\n",
        "  for i, batch in enumerate(test_dataloader):\n",
        "    # Perform a forward model pass\n",
        "    ## Put the batch onto a GPU\n",
        "    batch = {k: v.to(device) for (k, v) in batch.items()}\n",
        "\n",
        "    ## Forward Pass - Set no grad because we don't want to update parameters in validation\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    # Compute Metric\n",
        "    start_logits = outputs.start_logits\n",
        "    end_logits = outputs.end_logits\n",
        "\n",
        "    start_pos_predictions = torch.argmax(start_logits, dim = -1)\n",
        "    end_pos_predictions = torch.argmax(end_logits, dim = -1)\n",
        "\n",
        "    start_pos_labels = batch['start_positions']\n",
        "    end_pos_labels = batch['end_positions']\n",
        "\n",
        "    start_pos_metrics = compute_metrics(predictions= start_pos_predictions, labels=start_pos_labels)\n",
        "    end_pos_metrics = compute_metrics(predictions= end_pos_predictions, labels=end_pos_labels)\n",
        "\n",
        "    # Store Metrics\n",
        "    eval_start_pos_metrics.append(start_pos_metrics)\n",
        "    eval_end_pos_metrics.append(end_pos_metrics)\n",
        "\n",
        "    # Print Progress\n",
        "    print(f\"epoch {epoch} batch_number {i} start_pos_metrics {start_pos_metrics} end_pos_metrics {end_pos_metrics}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU5DDb7_SdB0"
      },
      "source": [
        "# Save and Load Tokenizer and Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-OQx2PGSf88",
        "outputId": "37fa38b1-5467-426b-985e-bcddcc0a2b6f"
      },
      "outputs": [],
      "source": [
        "# Suggested from Docs: https://huggingface.co/transformers/v1.2.0/serialization.html\n",
        "# Save Tokenizer and Model\n",
        "import os\n",
        "\n",
        "output_dir = \"./squad_qa_model/\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Step 1: Save a model, configuration and vocabulary that you have fine-tuned\n",
        "\n",
        "# If we have a distributed model, save only the encapsulated model\n",
        "# (it was wrapped in PyTorch DistributedDataParallel or DataParallel)\n",
        "model_to_save = model.module if hasattr(model, 'module') else model\n",
        "\n",
        "# If we save using the predefined names, we can load using `from_pretrained`\n",
        "WEIGHTS_NAME = \"pytorch_model.bin\"\n",
        "CONFIG_NAME = \"config.json\"\n",
        "output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
        "output_config_file = os.path.join(output_dir, CONFIG_NAME)\n",
        "\n",
        "torch.save(model.state_dict(), output_model_file)\n",
        "model.config.to_json_file(output_config_file)\n",
        "tokenizer.save_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVOmeHA6SmGc"
      },
      "outputs": [],
      "source": [
        "# Load Model\n",
        "pretrained_loaded_model = AutoModelForQuestionAnswering.from_pretrained(\"squad_qa_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXjM0h0C4s_F"
      },
      "source": [
        "# Inference\n",
        "\n",
        "Use model for inference using PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HY2_zVlo4xy3"
      },
      "outputs": [],
      "source": [
        "question = \"When was Pakistan founded?\"\n",
        "context = \"Pakistan was founded in 1948. It is a country based in South Asia with neighbours such as Iran and Afghanistan. It's majority population follows the religion of Islam.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8brWInxW486o"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"squad_qa_model\")\n",
        "inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
        "\n",
        "# Load Model\n",
        "pretrained_loaded_model = AutoModelForQuestionAnswering.from_pretrained(\"squad_qa_model\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = pretrained_loaded_model(**inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvRw8bBb5qA9"
      },
      "outputs": [],
      "source": [
        "answer_start_index = outputs.start_logits.argmax()\n",
        "answer_end_index = outputs.end_logits.argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tCnM4J9thMW9",
        "outputId": "e8fa6417-e163-4ccf-a5d4-dfedfe6eae71"
      },
      "outputs": [],
      "source": [
        "predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
        "tokenizer.decode(predict_answer_tokens)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b1f0dd2a2bf445384f705190479c7a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bbb7d11d9c24695a2eef2b77afd2b9d",
            "placeholder": "​",
            "style": "IPY_MODEL_64a996940ad04eae80f58bdb54e36356",
            "value": "Map: 100%"
          }
        },
        "0e76cb13e1754e71927fad2f6f4ed6f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f1a0ed81d74449dabdae5b7c7a5cb5c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21b63b5441244ee495eee48ab80648a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b1f0dd2a2bf445384f705190479c7a2",
              "IPY_MODEL_4bd1e03af5064022990978c0c65419be",
              "IPY_MODEL_8447f0aee645445299b6eb2e64d1e20f"
            ],
            "layout": "IPY_MODEL_e127d4a1f43f420fa539d017e65cb5f5"
          }
        },
        "2c60d4dafcd24bca979781a87c0c6aef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45c6ef85eaa342d687a1012d46853cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f1a0ed81d74449dabdae5b7c7a5cb5c",
            "placeholder": "​",
            "style": "IPY_MODEL_bfd4c6bbfa53491bbad60b1343694c00",
            "value": " 4000/4000 [00:05&lt;00:00, 732.62 examples/s]"
          }
        },
        "4bbb7d11d9c24695a2eef2b77afd2b9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bd1e03af5064022990978c0c65419be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcd50b1507504cc1ba151b9805d470ab",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e87ef095bdc40839fc28c59970cf3ef",
            "value": 1000
          }
        },
        "57fbbea4184f4a70ab445ada6c8c63e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e87ef095bdc40839fc28c59970cf3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64a996940ad04eae80f58bdb54e36356": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67bd2fc70a6a439c9051695a0ad3e801": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b97da18b34245e98e44511fe7ef5ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83af1af3748940e6b46306cbb8ad1925",
              "IPY_MODEL_6d681fdea4a44249a13ba89774d9dc87",
              "IPY_MODEL_45c6ef85eaa342d687a1012d46853cfa"
            ],
            "layout": "IPY_MODEL_e4d7baf85a424ac8ad52d13b386a79d3"
          }
        },
        "6d681fdea4a44249a13ba89774d9dc87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c60d4dafcd24bca979781a87c0c6aef",
            "max": 4000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67bd2fc70a6a439c9051695a0ad3e801",
            "value": 4000
          }
        },
        "83af1af3748940e6b46306cbb8ad1925": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a003b76d8a1c488d950166cead2c76f2",
            "placeholder": "​",
            "style": "IPY_MODEL_0e76cb13e1754e71927fad2f6f4ed6f0",
            "value": "Map: 100%"
          }
        },
        "8447f0aee645445299b6eb2e64d1e20f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbf3696088234fb49fc50d04bd1c9140",
            "placeholder": "​",
            "style": "IPY_MODEL_57fbbea4184f4a70ab445ada6c8c63e8",
            "value": " 1000/1000 [00:02&lt;00:00, 478.81 examples/s]"
          }
        },
        "a003b76d8a1c488d950166cead2c76f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcd50b1507504cc1ba151b9805d470ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfd4c6bbfa53491bbad60b1343694c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbf3696088234fb49fc50d04bd1c9140": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e127d4a1f43f420fa539d017e65cb5f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4d7baf85a424ac8ad52d13b386a79d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
