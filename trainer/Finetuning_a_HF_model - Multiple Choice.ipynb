{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1VQzGDJWUT2t4UNy0O2Y9uDJomoNCKyVq","timestamp":1690983421740},{"file_id":"18pk78C1u2-3DsvG5E3XsVZfHDYBfp5J4","timestamp":1690982780216}],"gpuType":"T4","authorship_tag":"ABX9TyMQ4LbXYgPBf1PUUKNtH7Fs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Finetune a BERT model on the SWAG Dataset\n","\n","Task Description: Involves producing several candidate answers along with a context.\n","\n","Original Tutorial: https://huggingface.co/docs/transformers/tasks/multiple_choice"],"metadata":{"id":"-YbIBXcexEdo"}},{"cell_type":"code","source":["!pip install -q transformers datasets evaluate accelerate"],"metadata":{"id":"rfiVGwyMxKEE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load SWAG dataset"],"metadata":{"id":"ocHWFEgMxUmn"}},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","swag = load_dataset(\"swag\", \"regular\")"],"metadata":{"id":"geYs0U6JxRxV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Look at the data\n","import pprint\n","pprint.pprint(swag['train'][0])\n","\n","# The text column is our model input\n"],"metadata":{"id":"OtcEya7Kx4-x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preprocessing\n","## Load Model\n","from transformers import AutoTokenizer\n","\n","checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)"],"metadata":{"id":"IbtvEgvlyEbI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Preprocessing\n","We need to create a preprocess function that we will apply to every instance in the dataset. The preprocess function needs to:\n","\n","1. Make four copies of the sent1 field and combine each of them with sent2 to recreate how a sentence starts.\n","\n","2. Combine sent2 with each of the four possible sentence endings.\n","\n","3. Flatten these two lists so you can tokenize them, and then unflatten them afterward so each example has a corresponding input_ids, attention_mask, and labels field."],"metadata":{"id":"sG9COA2JytEJ"}},{"cell_type":"code","source":["ending_names = [\"ending0\", \"ending1\", \"ending2\", \"ending3\"]\n","\n","\n","def preprocess_function(examples):\n","    first_sentences = [[context] * 4 for context in examples[\"sent1\"]]\n","    question_headers = examples[\"sent2\"]\n","    second_sentences = [\n","        [f\"{header} {examples[end][i]}\" for end in ending_names] for i, header in enumerate(question_headers)\n","    ]\n","\n","    first_sentences = sum(first_sentences, [])\n","    second_sentences = sum(second_sentences, [])\n","\n","    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n","    return {k: [v[i : i + 4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}"],"metadata":{"id":"5wnFWGL0epiW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apply preprocessing over entire dataset - batched = True process multiple elements of the datasets\n","tokenized_swag = swag.map(preprocess_function, batched = True)"],"metadata":{"id":"4pYKGGO7zzYM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_swag['train'][0]"],"metadata":{"id":"kBMLy0Jf0oHo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a batch of examples, with dynamic padding. Create the appropriate collator function\n","\n","\n","from dataclasses import dataclass\n","from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n","from typing import Optional, Union\n","import torch\n","\n","\n","@dataclass\n","class DataCollatorForMultipleChoice:\n","    \"\"\"\n","    Data collator that will dynamically pad the inputs for multiple choice received.\n","    \"\"\"\n","\n","    tokenizer: PreTrainedTokenizerBase\n","    padding: Union[bool, str, PaddingStrategy] = True\n","    max_length: Optional[int] = None\n","    pad_to_multiple_of: Optional[int] = None\n","\n","    def __call__(self, features):\n","        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n","        labels = [feature.pop(label_name) for feature in features]\n","        batch_size = len(features)\n","        num_choices = len(features[0][\"input_ids\"])\n","        flattened_features = [\n","            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n","        ]\n","        flattened_features = sum(flattened_features, [])\n","\n","        batch = self.tokenizer.pad(\n","            flattened_features,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors=\"pt\",\n","        )\n","\n","        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n","        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n","        return batch"],"metadata":{"id":"QOLxnG5Ze2OC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluate\n","\n","We want to create a `compute_metrics` function that monitors a metric during training. For this task, use the accuracy metric."],"metadata":{"id":"n84Gl8_qe9Ke"}},{"cell_type":"code","source":["import evaluate\n","\n","accuracy = evaluate.load(\"accuracy\")"],"metadata":{"id":"stvQKOl0fEBi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","    return accuracy.compute(predictions=predictions, references=labels)"],"metadata":{"id":"ZIWr_EjmfHo8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train using the Trainer API\n","The main training steps are:\n","\n","1. Define training hyperparameters using a model specific TrainingArguments function. At the end of each epoch, the Trainer will evaluate the defined loss metric and save the training checkpoint.\n","\n","2. Pass the training arguments to a Trainer function alongside the model, dataset, tokenizer, data collator.\n","\n","3. Call train() to finetune the model"],"metadata":{"id":"BjcuQs822Wkv"}},{"cell_type":"code","source":["from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n","\n","model = AutoModelForMultipleChoice.from_pretrained(\"bert-base-uncased\")"],"metadata":{"id":"nNB5hINQ3MLe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir=\"my_awesome_swag_model\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    push_to_hub=True,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_swag[\"train\"],\n","    eval_dataset=tokenized_swag[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()"],"metadata":{"id":"JInJ6PAd2XyU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.save_model(\"swag_multiple_model\")"],"metadata":{"id":"nm1XQNnI4g6I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# In this case, the tokenizer was not saved automatically, save it manually in the model folder for inference\n","tokenizer.save_pretrained(\"swag_multiple_model\", legacy_format=False)"],"metadata":{"id":"MYYZQz3E7oKV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Inference\n","\n","Use model for inference using PyTorch"],"metadata":{"id":"OXjM0h0C4s_F"}},{"cell_type":"code","source":["prompt = \"France has a bread law, Le Décret Pain, with strict rules on what is allowed in a traditional baguette.\"\n","candidate1 = \"The law does not apply to croissants and brioche.\"\n","candidate2 = \"The law applies to baguettes.\""],"metadata":{"id":"HY2_zVlo4xy3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"swag_multiple_model\")\n","inputs = tokenizer([[prompt, candidate1], [prompt, candidate2]], return_tensors=\"pt\", padding=True)\n","labels = torch.tensor(0).unsqueeze(0)"],"metadata":{"id":"8brWInxW486o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModelForMultipleChoice\n","\n","model = AutoModelForMultipleChoice.from_pretrained(\"swag_multiple_model\")\n","outputs = model(**{k: v.unsqueeze(0) for k, v in inputs.items()}, labels=labels)\n","logits = outputs.logits"],"metadata":{"id":"NjkHHQvn5Fr5","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_class = logits.argmax().item()\n","predicted_class"],"metadata":{"id":"nvRw8bBb5qA9"},"execution_count":null,"outputs":[]}]}